{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer Perceptrons -Programming quiz\n",
    "Below, you'll implement a forward pass through a 4x3x2 network, with sigmoid activation functions for both layers.\n",
    "\n",
    "Things to do:\n",
    "\n",
    "Calculate the input to the hidden layer.\n",
    "Calculate the hidden layer output.\n",
    "Calculate the input to the output layer.\n",
    "Calculate the output of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden-layer Output:\n",
      "[ 0.41492192  0.42604313  0.5002434 ]\n",
      "Output-layer Output:\n",
      "[ 0.49815196  0.48539772]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Network size\n",
    "N_input = 4\n",
    "N_hidden = 3\n",
    "N_output = 2\n",
    "\n",
    "np.random.seed(42)\n",
    "# Make some fake data\n",
    "X = np.random.randn(4)\n",
    "\n",
    "# X = 1 * 4\n",
    "##print(X)\n",
    "\n",
    "weights_in_hidden = np.random.normal(0, scale=0.1, size=(N_input, N_hidden))\n",
    "weights_hidden_out = np.random.normal(0, scale=0.1, size=(N_hidden, N_output))\n",
    "\n",
    "\n",
    "# TODO: Make a forward pass through the network\n",
    "\n",
    "hidden_layer_in = np.dot(X, weights_in_hidden)\n",
    "hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "\n",
    "print('Hidden-layer Output:')\n",
    "print(hidden_layer_out)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_out, weights_hidden_out)\n",
    "output_layer_out = sigmoid(output_layer_in)\n",
    "\n",
    "print('Output-layer Output:')\n",
    "print(output_layer_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation exercise\n",
    "Below, you'll implement the code to calculate one backpropagation update step for two sets of weights. I wrote the forward pass, your goal is to code the backward pass.\n",
    "\n",
    "Things to do\n",
    "\n",
    "1. Calculate the network error.\n",
    "2. Calculate the output layer error gradient.\n",
    "3. Use backpropagation to calculate the hidden layer error.\n",
    "4. Calculate the weight update steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11502656915\n",
      "Change in weights for hidden layer to output layer:\n",
      "None\n",
      "Change in weights for input layer to hidden layer:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate error\n",
    "error = target - output\n",
    "\n",
    "#print(error)\n",
    "\n",
    "# TODO: Calculate error gradient for output layer\n",
    "# error gradient = learnrate * (error) * f'(H) * x (x = input, H = wx)\n",
    "err_gradient_output =  np.dot(error,  sigmoid_derivate(output_layer_in))\n",
    "del_err_output = np.dot(hidden_layer_output,  learnrate * err_gradient_output)\n",
    "\n",
    "\n",
    "# TODO: Calculate error gradient for hidden layer\n",
    "err_gradient_hidden =  np.dot(del_err_output,  sigmoid_derivate(hidden_layer_input))\n",
    "del_err_hidden = np.dot(x,  learnrate * err_gradient_hidden)\n",
    "\n",
    "\n",
    "del_err_hidden = None\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "delta_w_h_o = None\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_o = None\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change in weights for hidden layer to output layer:\n",
      "[ 0.00804047  0.00555918]\n",
      "Change in weights for input layer to hidden layer:\n",
      "[[  1.77005547e-04  -5.11178506e-04]\n",
      " [  3.54011093e-05  -1.02235701e-04]\n",
      " [ -7.08022187e-05   2.04471402e-04]]\n"
     ]
    }
   ],
   "source": [
    "## class sample solution\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Calculate sigmoid\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivate(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "x = np.array([0.5, 0.1, -0.2])\n",
    "target = 0.6\n",
    "learnrate = 0.5\n",
    "\n",
    "weights_input_hidden = np.array([[0.5, -0.6],\n",
    "                                 [0.1, -0.2],\n",
    "                                 [0.1, 0.7]])\n",
    "\n",
    "weights_hidden_output = np.array([0.1, -0.3])\n",
    "\n",
    "## Forward pass\n",
    "hidden_layer_input = np.dot(x, weights_input_hidden)\n",
    "hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "\n",
    "output_layer_in = np.dot(hidden_layer_output, weights_hidden_output)\n",
    "output = sigmoid(output_layer_in)\n",
    "\n",
    "## Backwards pass\n",
    "## TODO: Calculate error\n",
    "error = target - output\n",
    "\n",
    "# TODO: Calculate error gradient for output layer\n",
    "## Terms == error gradient \n",
    "## err_gradient_output =  np.dot(error,  sigmoid_derivate(output_layer_in))\n",
    "## The del is confusing.\n",
    "del_err_output = np.dot(error, sigmoid_derivate(output_layer_in))\n",
    "\n",
    "# TODO: Calculate change in weights for hidden layer to output layer\n",
    "# change_in_weigths = learnrate * (error) * F'(H) * x (x = input, H = wx, note f' ~ w, \n",
    "##                                                                 H is before applying the sigmoid function F)\n",
    "delta_w_h_o = learnrate * del_err_output * hidden_layer_output\n",
    "\n",
    "# TODO: Calculate error gradient for hidden layer\n",
    "del_err_hidden = np.dot(del_err_output, weights_hidden_output) * sigmoid_derivate(hidden_layer_input)\n",
    "                 ## This term is nothing but propogate the error proportional to the weigths.\n",
    "                 ## look at the last section of the notebook in case of any Qs.\n",
    "                 ## Backpropagation for multi layer perceptronâ€™s\n",
    "\n",
    "# TODO: Calculate change in weights for input layer to hidden layer\n",
    "delta_w_i_o = learnrate * del_err_hidden * x[:, None] ## the last term is making x to a column vector.\n",
    "\n",
    "print('Change in weights for hidden layer to output layer:')\n",
    "print(delta_w_h_o)\n",
    "print('Change in weights for input layer to hidden layer:')\n",
    "print(delta_w_i_o)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
